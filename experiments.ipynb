{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cd3f150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/ravichoudhary/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('gutenberg')\n",
    "\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "#load the data set\n",
    "data = gutenberg.raw('shakespeare-hamlet.txt')\n",
    "\n",
    "#save data in file\n",
    "with open('hemlet.txt','w') as file:\n",
    "    file.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c78995",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c7704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b3e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "with open(\"hemlet.txt\",'r') as file:\n",
    "    text=file.read().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36682d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4818"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize the text-creating indexes for words\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index)+1\n",
    "total_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8585a26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence=[]\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1,len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequence.append(n_gram_sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e6f98d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_length = max([len(x) for x in input_sequence])\n",
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32d87790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,    1,  687],\n",
       "       [   0,    0,    0, ...,    1,  687,    4],\n",
       "       [   0,    0,    0, ...,  687,    4,   45],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    4,   45, 1047],\n",
       "       [   0,    0,    0, ...,   45, 1047,    4],\n",
       "       [   0,    0,    0, ..., 1047,    4,  193]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence = np.array(pad_sequences(input_sequence,max_sequence_length,padding='pre'))\n",
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d74eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load predictors and labels\n",
    "x,y = input_sequence[:,:-1],input_sequence[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "936ed90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "y=tf.keras.utils.to_categorical(y,num_classes=total_words)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37275f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset in the training and testing split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a1303ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 13:18:38.540055: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2\n",
      "2025-09-17 13:18:38.540490: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 8.00 GB\n",
      "2025-09-17 13:18:38.540510: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 2.67 GB\n",
      "2025-09-17 13:18:38.540872: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-09-17 13:18:38.541425: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#model using LSTM RNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense,Dropout,GRU\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words,100,input_length=max_sequence_length-1))\n",
    "model.add(LSTM(150,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(total_words,activation='softmax'))\n",
    "\n",
    "#complie the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43ed8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model using GRU RNN\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(total_words,100,input_length=max_sequence_length-1))\n",
    "model1.add(GRU(150,return_sequences=True))\n",
    "model1.add(Dropout(0.2))\n",
    "model1.add(GRU(100))\n",
    "model1.add(Dense(total_words,activation='softmax'))\n",
    "\n",
    "#complie the model\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "589dfe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#early_stopping = EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "580499f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 13, 100)           481800    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 13, 150)           150600    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 13, 150)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               100400    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4818)              486618    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1219418 (4.65 MB)\n",
      "Trainable params: 1219418 (4.65 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c705e285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-17 13:19:11.049140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "644/644 [==============================] - 25s 34ms/step - loss: 6.8952 - accuracy: 0.0331 - val_loss: 6.7930 - val_accuracy: 0.0344\n",
      "Epoch 2/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 6.4518 - accuracy: 0.0376 - val_loss: 6.8933 - val_accuracy: 0.0422\n",
      "Epoch 3/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 6.3168 - accuracy: 0.0452 - val_loss: 6.9453 - val_accuracy: 0.0523\n",
      "Epoch 4/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 6.1803 - accuracy: 0.0510 - val_loss: 6.9663 - val_accuracy: 0.0505\n",
      "Epoch 5/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 6.0410 - accuracy: 0.0549 - val_loss: 7.0449 - val_accuracy: 0.0536\n",
      "Epoch 6/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.9030 - accuracy: 0.0605 - val_loss: 7.1021 - val_accuracy: 0.0595\n",
      "Epoch 7/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.7735 - accuracy: 0.0686 - val_loss: 7.1519 - val_accuracy: 0.0624\n",
      "Epoch 8/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.6389 - accuracy: 0.0762 - val_loss: 7.2624 - val_accuracy: 0.0657\n",
      "Epoch 9/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.5062 - accuracy: 0.0844 - val_loss: 7.3052 - val_accuracy: 0.0670\n",
      "Epoch 10/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.3830 - accuracy: 0.0902 - val_loss: 7.3598 - val_accuracy: 0.0672\n",
      "Epoch 11/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.2642 - accuracy: 0.0951 - val_loss: 7.5074 - val_accuracy: 0.0686\n",
      "Epoch 12/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.1447 - accuracy: 0.1044 - val_loss: 7.5693 - val_accuracy: 0.0680\n",
      "Epoch 13/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 5.0276 - accuracy: 0.1084 - val_loss: 7.6687 - val_accuracy: 0.0680\n",
      "Epoch 14/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.9109 - accuracy: 0.1137 - val_loss: 7.8011 - val_accuracy: 0.0676\n",
      "Epoch 15/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.7985 - accuracy: 0.1190 - val_loss: 7.8857 - val_accuracy: 0.0663\n",
      "Epoch 16/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.6866 - accuracy: 0.1246 - val_loss: 8.0142 - val_accuracy: 0.0666\n",
      "Epoch 17/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.5782 - accuracy: 0.1291 - val_loss: 8.1631 - val_accuracy: 0.0674\n",
      "Epoch 18/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.4724 - accuracy: 0.1335 - val_loss: 8.2789 - val_accuracy: 0.0639\n",
      "Epoch 19/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.3693 - accuracy: 0.1407 - val_loss: 8.4424 - val_accuracy: 0.0641\n",
      "Epoch 20/50\n",
      "644/644 [==============================] - 22s 33ms/step - loss: 4.2693 - accuracy: 0.1496 - val_loss: 8.5693 - val_accuracy: 0.0666\n",
      "Epoch 21/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 4.1691 - accuracy: 0.1587 - val_loss: 8.7036 - val_accuracy: 0.0661\n",
      "Epoch 22/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 4.0772 - accuracy: 0.1734 - val_loss: 8.8455 - val_accuracy: 0.0651\n",
      "Epoch 23/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.9870 - accuracy: 0.1847 - val_loss: 8.9828 - val_accuracy: 0.0628\n",
      "Epoch 24/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.9051 - accuracy: 0.1975 - val_loss: 9.1014 - val_accuracy: 0.0624\n",
      "Epoch 25/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.8187 - accuracy: 0.2113 - val_loss: 9.2556 - val_accuracy: 0.0633\n",
      "Epoch 26/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.7451 - accuracy: 0.2247 - val_loss: 9.3282 - val_accuracy: 0.0600\n",
      "Epoch 27/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.6738 - accuracy: 0.2378 - val_loss: 9.4604 - val_accuracy: 0.0618\n",
      "Epoch 28/50\n",
      "644/644 [==============================] - 17s 27ms/step - loss: 3.6004 - accuracy: 0.2527 - val_loss: 9.5789 - val_accuracy: 0.0645\n",
      "Epoch 29/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.5304 - accuracy: 0.2619 - val_loss: 9.7103 - val_accuracy: 0.0579\n",
      "Epoch 30/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 3.4668 - accuracy: 0.2728 - val_loss: 9.8267 - val_accuracy: 0.0616\n",
      "Epoch 31/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.4076 - accuracy: 0.2842 - val_loss: 9.9496 - val_accuracy: 0.0616\n",
      "Epoch 32/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.3512 - accuracy: 0.2955 - val_loss: 10.0348 - val_accuracy: 0.0595\n",
      "Epoch 33/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.2852 - accuracy: 0.3088 - val_loss: 10.1200 - val_accuracy: 0.0591\n",
      "Epoch 34/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.2332 - accuracy: 0.3131 - val_loss: 10.2438 - val_accuracy: 0.0608\n",
      "Epoch 35/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.1812 - accuracy: 0.3225 - val_loss: 10.3032 - val_accuracy: 0.0616\n",
      "Epoch 36/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.1322 - accuracy: 0.3302 - val_loss: 10.4036 - val_accuracy: 0.0581\n",
      "Epoch 37/50\n",
      "644/644 [==============================] - 18s 29ms/step - loss: 3.0814 - accuracy: 0.3400 - val_loss: 10.5430 - val_accuracy: 0.0602\n",
      "Epoch 38/50\n",
      "644/644 [==============================] - 22s 34ms/step - loss: 3.0371 - accuracy: 0.3484 - val_loss: 10.5840 - val_accuracy: 0.0604\n",
      "Epoch 39/50\n",
      "644/644 [==============================] - 19s 29ms/step - loss: 2.9854 - accuracy: 0.3593 - val_loss: 10.6541 - val_accuracy: 0.0600\n",
      "Epoch 40/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 2.9424 - accuracy: 0.3686 - val_loss: 10.7562 - val_accuracy: 0.0591\n",
      "Epoch 41/50\n",
      "644/644 [==============================] - 19s 29ms/step - loss: 2.9007 - accuracy: 0.3713 - val_loss: 10.8513 - val_accuracy: 0.0585\n",
      "Epoch 42/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 2.8557 - accuracy: 0.3834 - val_loss: 10.9177 - val_accuracy: 0.0593\n",
      "Epoch 43/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 2.8173 - accuracy: 0.3902 - val_loss: 10.9826 - val_accuracy: 0.0571\n",
      "Epoch 44/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 2.7771 - accuracy: 0.3956 - val_loss: 11.0701 - val_accuracy: 0.0573\n",
      "Epoch 45/50\n",
      "644/644 [==============================] - 17s 27ms/step - loss: 2.7398 - accuracy: 0.4033 - val_loss: 11.1770 - val_accuracy: 0.0560\n",
      "Epoch 46/50\n",
      "644/644 [==============================] - 17s 27ms/step - loss: 2.7003 - accuracy: 0.4136 - val_loss: 11.2350 - val_accuracy: 0.0567\n",
      "Epoch 47/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 2.6598 - accuracy: 0.4154 - val_loss: 11.3065 - val_accuracy: 0.0565\n",
      "Epoch 48/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 2.6233 - accuracy: 0.4269 - val_loss: 11.3855 - val_accuracy: 0.0563\n",
      "Epoch 49/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 2.5953 - accuracy: 0.4318 - val_loss: 11.4295 - val_accuracy: 0.0546\n",
      "Epoch 50/50\n",
      "644/644 [==============================] - 17s 27ms/step - loss: 2.5611 - accuracy: 0.4398 - val_loss: 11.5414 - val_accuracy: 0.0548\n"
     ]
    }
   ],
   "source": [
    "#train out LSTM RNN model\n",
    "history=model.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe8e221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "644/644 [==============================] - 24s 32ms/step - loss: 7.0277 - accuracy: 0.0286 - val_loss: 6.9007 - val_accuracy: 0.0344\n",
      "Epoch 2/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 6.4870 - accuracy: 0.0400 - val_loss: 6.9027 - val_accuracy: 0.0513\n",
      "Epoch 3/50\n",
      "644/644 [==============================] - 27s 42ms/step - loss: 6.2642 - accuracy: 0.0518 - val_loss: 6.9406 - val_accuracy: 0.0560\n",
      "Epoch 4/50\n",
      "644/644 [==============================] - 21s 33ms/step - loss: 6.0424 - accuracy: 0.0675 - val_loss: 6.9233 - val_accuracy: 0.0680\n",
      "Epoch 5/50\n",
      "644/644 [==============================] - 22s 33ms/step - loss: 5.7749 - accuracy: 0.0846 - val_loss: 6.9247 - val_accuracy: 0.0707\n",
      "Epoch 6/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 5.5194 - accuracy: 0.0924 - val_loss: 7.0320 - val_accuracy: 0.0742\n",
      "Epoch 7/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 5.2708 - accuracy: 0.1040 - val_loss: 7.1007 - val_accuracy: 0.0713\n",
      "Epoch 8/50\n",
      "644/644 [==============================] - 20s 31ms/step - loss: 5.0358 - accuracy: 0.1138 - val_loss: 7.1653 - val_accuracy: 0.0767\n",
      "Epoch 9/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.8073 - accuracy: 0.1287 - val_loss: 7.3238 - val_accuracy: 0.0762\n",
      "Epoch 10/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.5865 - accuracy: 0.1454 - val_loss: 7.4433 - val_accuracy: 0.0727\n",
      "Epoch 11/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 4.3815 - accuracy: 0.1698 - val_loss: 7.5523 - val_accuracy: 0.0699\n",
      "Epoch 12/50\n",
      "644/644 [==============================] - 17s 27ms/step - loss: 4.1826 - accuracy: 0.1918 - val_loss: 7.6175 - val_accuracy: 0.0729\n",
      "Epoch 13/50\n",
      "644/644 [==============================] - 18s 29ms/step - loss: 4.0000 - accuracy: 0.2188 - val_loss: 7.7456 - val_accuracy: 0.0703\n",
      "Epoch 14/50\n",
      "644/644 [==============================] - 20s 31ms/step - loss: 3.8311 - accuracy: 0.2399 - val_loss: 7.8599 - val_accuracy: 0.0657\n",
      "Epoch 15/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.6685 - accuracy: 0.2680 - val_loss: 7.9684 - val_accuracy: 0.0692\n",
      "Epoch 16/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 3.5163 - accuracy: 0.2931 - val_loss: 8.0389 - val_accuracy: 0.0690\n",
      "Epoch 17/50\n",
      "644/644 [==============================] - 17s 27ms/step - loss: 3.3769 - accuracy: 0.3149 - val_loss: 8.1504 - val_accuracy: 0.0647\n",
      "Epoch 18/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 3.2502 - accuracy: 0.3366 - val_loss: 8.2671 - val_accuracy: 0.0668\n",
      "Epoch 19/50\n",
      "644/644 [==============================] - 17s 27ms/step - loss: 3.1288 - accuracy: 0.3596 - val_loss: 8.3377 - val_accuracy: 0.0639\n",
      "Epoch 20/50\n",
      "644/644 [==============================] - 17s 27ms/step - loss: 3.0122 - accuracy: 0.3783 - val_loss: 8.4152 - val_accuracy: 0.0649\n",
      "Epoch 21/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 2.9111 - accuracy: 0.3932 - val_loss: 8.5031 - val_accuracy: 0.0616\n",
      "Epoch 22/50\n",
      "644/644 [==============================] - 19s 30ms/step - loss: 2.8111 - accuracy: 0.4131 - val_loss: 8.5697 - val_accuracy: 0.0639\n",
      "Epoch 23/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 2.7201 - accuracy: 0.4303 - val_loss: 8.6555 - val_accuracy: 0.0655\n",
      "Epoch 24/50\n",
      "644/644 [==============================] - 16s 25ms/step - loss: 2.6231 - accuracy: 0.4483 - val_loss: 8.7368 - val_accuracy: 0.0631\n",
      "Epoch 25/50\n",
      "644/644 [==============================] - 16s 25ms/step - loss: 2.5510 - accuracy: 0.4633 - val_loss: 8.8106 - val_accuracy: 0.0610\n",
      "Epoch 26/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 2.4750 - accuracy: 0.4736 - val_loss: 8.8910 - val_accuracy: 0.0620\n",
      "Epoch 27/50\n",
      "644/644 [==============================] - 16s 25ms/step - loss: 2.4025 - accuracy: 0.4917 - val_loss: 8.9749 - val_accuracy: 0.0624\n",
      "Epoch 28/50\n",
      "644/644 [==============================] - 16s 25ms/step - loss: 2.3297 - accuracy: 0.5030 - val_loss: 9.0239 - val_accuracy: 0.0628\n",
      "Epoch 29/50\n",
      "644/644 [==============================] - 16s 25ms/step - loss: 2.2645 - accuracy: 0.5150 - val_loss: 9.1101 - val_accuracy: 0.0610\n",
      "Epoch 30/50\n",
      "644/644 [==============================] - 16s 25ms/step - loss: 2.2060 - accuracy: 0.5255 - val_loss: 9.1562 - val_accuracy: 0.0612\n",
      "Epoch 31/50\n",
      "644/644 [==============================] - 17s 27ms/step - loss: 2.1464 - accuracy: 0.5402 - val_loss: 9.2517 - val_accuracy: 0.0651\n",
      "Epoch 32/50\n",
      "644/644 [==============================] - 18s 27ms/step - loss: 2.0872 - accuracy: 0.5493 - val_loss: 9.3116 - val_accuracy: 0.0649\n",
      "Epoch 33/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 2.0319 - accuracy: 0.5611 - val_loss: 9.3994 - val_accuracy: 0.0620\n",
      "Epoch 34/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 1.9812 - accuracy: 0.5674 - val_loss: 9.4291 - val_accuracy: 0.0606\n",
      "Epoch 35/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 1.9387 - accuracy: 0.5753 - val_loss: 9.4913 - val_accuracy: 0.0606\n",
      "Epoch 36/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 1.8871 - accuracy: 0.5879 - val_loss: 9.5702 - val_accuracy: 0.0641\n",
      "Epoch 37/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 1.8454 - accuracy: 0.5945 - val_loss: 9.6184 - val_accuracy: 0.0612\n",
      "Epoch 38/50\n",
      "644/644 [==============================] - 17s 26ms/step - loss: 1.8098 - accuracy: 0.6032 - val_loss: 9.6697 - val_accuracy: 0.0618\n",
      "Epoch 39/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 1.7699 - accuracy: 0.6122 - val_loss: 9.7299 - val_accuracy: 0.0626\n",
      "Epoch 40/50\n",
      "644/644 [==============================] - 19s 30ms/step - loss: 1.7316 - accuracy: 0.6179 - val_loss: 9.7969 - val_accuracy: 0.0581\n",
      "Epoch 41/50\n",
      "644/644 [==============================] - 23s 35ms/step - loss: 1.6989 - accuracy: 0.6239 - val_loss: 9.8645 - val_accuracy: 0.0585\n",
      "Epoch 42/50\n",
      "644/644 [==============================] - 19s 29ms/step - loss: 1.6586 - accuracy: 0.6298 - val_loss: 9.9081 - val_accuracy: 0.0604\n",
      "Epoch 43/50\n",
      "644/644 [==============================] - 33s 51ms/step - loss: 1.6262 - accuracy: 0.6372 - val_loss: 9.9668 - val_accuracy: 0.0593\n",
      "Epoch 44/50\n",
      "644/644 [==============================] - 19s 30ms/step - loss: 1.6062 - accuracy: 0.6418 - val_loss: 10.0206 - val_accuracy: 0.0610\n",
      "Epoch 45/50\n",
      "644/644 [==============================] - 20s 30ms/step - loss: 1.5691 - accuracy: 0.6490 - val_loss: 10.0786 - val_accuracy: 0.0618\n",
      "Epoch 46/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 1.5398 - accuracy: 0.6562 - val_loss: 10.1539 - val_accuracy: 0.0610\n",
      "Epoch 47/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 1.5150 - accuracy: 0.6615 - val_loss: 10.1851 - val_accuracy: 0.0579\n",
      "Epoch 48/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 1.4887 - accuracy: 0.6676 - val_loss: 10.2206 - val_accuracy: 0.0577\n",
      "Epoch 49/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 1.4716 - accuracy: 0.6687 - val_loss: 10.2568 - val_accuracy: 0.0581\n",
      "Epoch 50/50\n",
      "644/644 [==============================] - 18s 28ms/step - loss: 1.4399 - accuracy: 0.6746 - val_loss: 10.3380 - val_accuracy: 0.0573\n"
     ]
    }
   ],
   "source": [
    "#train our GRU RNN model\n",
    "history1=model1.fit(x_train,y_train,epochs=50,validation_data=(x_test,y_test),verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65387755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(model,tokenizer,text,max_sequence_len):\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    if len(token_list)>=max_sequence_len:\n",
    "        token_list = token_list[-(max_sequence_len-1):]\n",
    "    token_list = pad_sequences([token_list],maxlen=max_sequence_len-1,padding='pre')\n",
    "    predicted=model.predict(token_list)\n",
    "    predicted_word_index=np.argmax(predicted,axis=1)\n",
    "    for word ,index in tokenizer.word_index.items():\n",
    "        if index==predicted_word_index:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccf85307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input text : My Lord, I came to see your Fathers\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "predicted next word : death\n"
     ]
    }
   ],
   "source": [
    "input_text = \"My Lord, I came to see your Fathers\"\n",
    "print(f\"input text : {input_text}\")\n",
    "max_sequence_len = model1.input_shape[1]+1\n",
    "next_word = predict_next_word(model1,tokenizer,input_text,max_sequence_len)\n",
    "print(f\"predicted next word : {next_word}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92f21674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ravichoudhary/Desktop/genAI_projects/myenv/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#save our model\n",
    "model1.save('next_word_LSTM.h5')\n",
    "\n",
    "#save out tokenizer\n",
    "import pickle\n",
    "with open('tokenizer.pkl','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
